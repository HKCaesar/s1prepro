{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cDL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HKCaesar/s1prepro/blob/master/cDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "TJ1tbr7nyd1h",
        "colab_type": "code",
        "outputId": "34ad54c6-70d2-43f0-f1d1-8e8a65f49f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1801
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256))\n",
        "model.add(tf.keras.layers.Activation('elu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Activation('softmax'))\n",
        "model.summary()\n",
        "import os\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "tpu_model.compile(\n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=1e-3, ),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "def train_gen(batch_size):\n",
        "  while True:\n",
        "    offset = np.random.randint(0, x_train.shape[0] - batch_size)\n",
        "    yield x_train[offset:offset+batch_size], y_train[offset:offset + batch_size]\n",
        "    \n",
        "\n",
        "tpu_model.fit_generator(\n",
        "    train_gen(1024),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=100,\n",
        "    validation_data=(x_test, y_test),\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 128)       204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 256)         819456    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               590080    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,619,470\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 386\n",
            "_________________________________________________________________\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.23.15.218:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 12404221056269560288)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12660211826814532581)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 13799808080964844248)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12490392202622880718)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2636408615324330637)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 3633351747625316982)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 4726437838459847283)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4744852482574062007)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11186468871532855065)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4817733646994950503)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 3134389709369527299)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 746748961526966342)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "Epoch 1/10\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name=u'core_id0'), TensorSpec(shape=(128, 28, 28, 1), dtype=tf.float32, name=u'batch_normalization_input_10'), TensorSpec(shape=(128, 1), dtype=tf.float32, name=u'activation_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for batch_normalization_input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 3.65983891487 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.9128 - sparse_categorical_accuracy: 0.7319INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(128,), dtype=tf.int32, name=u'core_id_10'), TensorSpec(shape=(128, 28, 28, 1), dtype=tf.float32, name=u'batch_normalization_input_10'), TensorSpec(shape=(128, 1), dtype=tf.float32, name=u'activation_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for batch_normalization_input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 2.11896491051 secs\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(98,), dtype=tf.int32, name=u'core_id_10'), TensorSpec(shape=(98, 28, 28, 1), dtype=tf.float32, name=u'batch_normalization_input_10'), TensorSpec(shape=(98, 1), dtype=tf.float32, name=u'activation_1_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for batch_normalization_input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 2.15392303467 secs\n",
            "100/100 [==============================] - 20s 203ms/step - loss: 0.9084 - sparse_categorical_accuracy: 0.7331 - val_loss: 1.1827 - val_sparse_categorical_accuracy: 0.5798\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4393 - sparse_categorical_accuracy: 0.8489 - val_loss: 0.9091 - val_sparse_categorical_accuracy: 0.7219\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.3575 - sparse_categorical_accuracy: 0.8749 - val_loss: 0.8334 - val_sparse_categorical_accuracy: 0.6981\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.3027 - sparse_categorical_accuracy: 0.8921 - val_loss: 0.6571 - val_sparse_categorical_accuracy: 0.7596\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.2607 - sparse_categorical_accuracy: 0.9058 - val_loss: 0.3328 - val_sparse_categorical_accuracy: 0.8807\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.2336 - sparse_categorical_accuracy: 0.9154 - val_loss: 0.3156 - val_sparse_categorical_accuracy: 0.8831\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2096 - sparse_categorical_accuracy: 0.9230 - val_loss: 0.2715 - val_sparse_categorical_accuracy: 0.9050\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.1886 - sparse_categorical_accuracy: 0.9304 - val_loss: 0.2317 - val_sparse_categorical_accuracy: 0.9223\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.1706 - sparse_categorical_accuracy: 0.9364 - val_loss: 0.2359 - val_sparse_categorical_accuracy: 0.9237\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.1546 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.2317 - val_sparse_categorical_accuracy: 0.9210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd38af52bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "jxKLtz_b4NHL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = \"/content/drive/My Drive/Colab Notebooks\" #/content/sample_data\n",
        "os.listdir(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ob3-pSgm5Mqi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0A8xtC9s_Y4L",
        "colab_type": "code",
        "outputId": "a33db638-7d4a-4a1b-8eb0-77f45bbc4af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "! cat sample_data/README.md"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This directory includes a few sample datasets to get you started.\n",
            "\n",
            "* `california_housing_data*.csv` is California housing data from the 1990 US\n",
            "  Census; more information is available at:\n",
            "  https://developers.google.com/machine-learning/crash-course/california-housing-data-description\n",
            "\n",
            "* `mnist_*.csv` is a small sample of the [MNIST\n",
            "  database](https://en.wikipedia.org/wiki/MNIST_database), which is described\n",
            "  at: http://yann.lecun.com/exdb/mnist/\n",
            "\n",
            "* `anscombe.json` contains a copy of [Anscombe's\n",
            " quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet);\n",
            "  it was originally described in\n",
            "\n",
            "      Anscombe, F. J. (1973). 'Graphs in Statistical Analysis'. American Statistician. 27 (1): 17-21. JSTOR 2682899.\n",
            "\n",
            "  and our copy was prepared by the [vega_datasets library](https://github.com/altair-viz/vega_datasets/blob/4f67bdaad10f45e3549984e17e1b3088c731503d/vega_datasets/_data/anscombe.json).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}